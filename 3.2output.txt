Model: Naive Bayes

== Error on Training Data ==

			      500  |  1000   |   1500   |   2000  |  2500  |  3000  |  3500  |  4000  |  4500  |  5000  | 5500
			 ________________________________________________________________________________________________________
Correctly Classified	|   61.5%  |  63.6%  | 62.2667% | 61.775% | 61.54% | 61.55% |59.8571%| 60.25% |59.9556%| 59.61% |60.2909%|
Incorrectly Classified 	|   38.5%  |  36.4%  | 37.7333% | 38.225% | 38.46% | 38.4 % |40.1429%| 39.75% |40.0444%| 40.39% |39.7091%|



== Error on Test Data == 

			     500   |   1000  |   1500   |  2000   |  2500  |   3000 |  3500  |  4000  |  4500  |  5000  | 5500
			 ________________________________________________________________________________________________________
Correctly Classified	| 55.4318% | 54.039% | 53.4819% |53.4819% |52.0891%|52.6462%|54.8747%|54.5961%|54.3175%|54.3175%|53.4819%|
Incorrectly Classified 	| 44.5682% | 45.961% | 46.5181% |46.5181% |47.9109%|47.3538%|45.1253%|45.4039%|45.6825%|45.6825%|46.5181%|



Discussion:
****************************************
There does not seem to be a clear correlation between the size of the
training set and its accuracy (this applies to both training and test 
accuracies) although it should be noted that the best test accuracy was obtained 
with the smallest set.

We can see from the table that there is a steady drop in test accuracy from
the 500 training set to the 3000 one. After that, there is a spike and it
continues relatively stable up to the 5500 set. 

These results are in contradiction of the general notion that as the size of 
the dataset increases, so does our accuracy. This idea has been made popular by 
the recent rise in notoriety of deep learning, which depends on large amounts
of data to reach a good performance; but as we can see from our experiment, this 
doesn't hold up for other more traditional methods such as SVM and Naive Bayes. 
Furthermore, based on this observation, we could also hypothesize that for 
relatively small datasets, using traditional methods would be a better choice 
over modern deep learning techniques.
